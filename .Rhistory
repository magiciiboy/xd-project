print(nrow(dat))
# Summarize the data characteristics
# head(dat)
# summary(dat)
# str(dat)
# Treat NA, zeros values
cols_NA <- unlist(lapply(dat, function(x) any(is.na(x))))
cols_0s <- unlist(lapply(dat, function(x) any(x==0)))
cols_NA <- cols_NA[cols_NA==T]
cols_0s <- cols_0s[cols_0s==T]
print(names(cols_NA))
print(names(cols_0s))
for (cname in names(cols_0s)) {
if (cname != 'PRCentrality') {
dat[cname] -> col
col[col==0] <- ZERO_REPLACEMENT_CONSTANT
dat[cname] <- col
}
}
# Preprocess the data
dat$C_i <- dat$t_pubs_citations
dat$r_i <- dat$SchoolRank
dat$dollar_NSF <- dat$t_deflated_nsf
dat$dollar_NIH <- dat$t_deflated_nih
dat$C_PR <- dat$PRCentrality
dat$C_B <- dat$BetCentrality
dat$O <- dat$XDIndicator
# dat %>% mutate(C_D=Degree)
# Remove old columns
# dat$t_pubs_citations <- NULL
# dat$SchoolRank <- NULL
# dat$t_deflated_nsf <- NULL
# dat$t_deflated_nih <- NULL
# dat$PRCentrality <- NULL
# dat$BetCentrality <- NULL
# Build models
# str(dat)
# Model 1: CV
print(nrow(dat))
model_CV <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ factor(O) + factor(Y05yr), data=dat)
summary(model_CV)
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_CV_Net <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_CV_Net)
std_beta(model_CV_Net)
# install.packages('plm')
# install.packages('sjstats')
library(sjstats)
# install.packages('plm')
# install.packages('sjstats')
library(sjstats)
library(plm)
library(dplyr)
ZERO_REPLACEMENT_CONSTANT <- 1
ZERO_REPLACEMENT_CONSTANT_NUM <- 1
ZERO_REPLACEMENT_CONSTANT_AMT <- 1
dat <- read.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
print(colnames(dat))
print(nrow(dat))
# Summarize the data characteristics
# head(dat)
# summary(dat)
# str(dat)
# Treat NA, zeros values
cols_NA <- unlist(lapply(dat, function(x) any(is.na(x))))
cols_0s <- unlist(lapply(dat, function(x) any(x==0)))
cols_NA <- cols_NA[cols_NA==T]
cols_0s <- cols_0s[cols_0s==T]
print(names(cols_NA))
print(names(cols_0s))
# Note: No NA values
# List of columns having 0s values
# [1] "i10index"       "mean_of_IF"     "num_nsf"        "t_deflated_nsf" "num_nih"        "t_deflated_nih"
# [7] "KTotal"         "KDirect"        "KMediated"      "Chi"            "BetCentrality"  "PRCentrality"
# Note: This way seems does not work really well
# Parameters of # of grants and total amount of grants are not close to the ones in the paper
# for (cname in names(cols_0s)) {
#  if (cname != 'PRCentrality') {
#    dat[cname] -> col
#    col[col==0] <- ZERO_REPLACEMENT_CONSTANT
#    dat[cname] <- col
#  }
# }
#
# Try this manual way
col_num_nsf <- dat$num_nsf
col_num_nsf[col_num_nsf==0] <- ZERO_REPLACEMENT_CONSTANT_NUM
dat$num_nsf <- col_num_nsf
col_num_nih <- dat$num_nih
col_num_nih[col_num_nih==0] <- ZERO_REPLACEMENT_CONSTANT_NUM
dat$num_nih <- col_num_nih
col_t_deflated_nsf <- dat$t_deflated_nsf
col_t_deflated_nsf[col_t_deflated_nsf==0] <- ZERO_REPLACEMENT_CONSTANT_AMT
dat$t_deflated_nsf <- col_t_deflated_nsf
col_t_deflated_nih <- dat$t_deflated_nih
col_t_deflated_nih[col_t_deflated_nih==0] <- ZERO_REPLACEMENT_CONSTANT_AMT
dat$t_deflated_nih <- col_t_deflated_nih
# Rename the column name
dat$C_i <- dat$t_pubs_citations
dat$r_i <- dat$SchoolRank
dat$dollar_NSF <- dat$t_deflated_nsf
dat$dollar_NIH <- dat$t_deflated_nih
dat$C_PR <- dat$PRCentrality
dat$C_B <- dat$BetCentrality
dat$O <- dat$XDIndicator
# dat %>% mutate(C_D=Degree)
# Remove old columns
# dat$t_pubs_citations <- NULL
# dat$SchoolRank <- NULL
# dat$t_deflated_nsf <- NULL
# dat$t_deflated_nih <- NULL
# dat$PRCentrality <- NULL
# dat$BetCentrality <- NULL
# Build models
# str(dat)
# Model 1: CV
print(nrow(dat))
model_CV <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ factor(O) + factor(Y05yr), data=dat)
summary(model_CV)
# Model 2: CV
# Remove row having NA (Ex: pagerank). Only keep 3900 nodes in the network.
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_CV_Net <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_CV_Net)
# Model 3: CV (Standardized)
model_CV_Net_std <- lm(log(C_i) ~ scale(log(r_i)) + scale(log(h_index)) + scale(log(dollar_NSF))
+ scale(log(num_nsf)) + scale(log(dollar_NIH)) + scale(log(num_nih))
+ scale(log(C_PR)) + scale(Chi)
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_CV_Net_std)
# Summary
# Model CV:
c(model_CV$coef["log(r_i)"][[1]],
model_CV$coef["log(h_index)"][[1]],
model_CV$coef["log(dollar_NSF)"][[1]],
model_CV$coef["log(num_nsf)"][[1]],
model_CV$coef["log(dollar_NIH)"][[1]],
model_CV$coef["log(num_nih)"][[1]],
model_CV$coef["(Intercept)"][[1]])
# Model CV + Network:
c(model_CV_Net$coef["log(r_i)"][[1]],
model_CV_Net$coef["log(h_index)"][[1]],
model_CV_Net$coef["log(dollar_NSF)"][[1]],
model_CV_Net$coef["log(num_nsf)"][[1]],
model_CV_Net$coef["log(dollar_NIH)"][[1]],
model_CV_Net$coef["log(num_nih)"][[1]],
model_CV_Net$coef["log(C_PR)"][[1]],
model_CV_Net$coef["Chi"][[1]],
model_CV_Net$coef["(Intercept)"][[1]])
# Model CV + Network (Standardized):
c(model_CV_Net_std$coef["scale(log(r_i))"][[1]],
model_CV_Net_std$coef["scale(log(h_index))"][[1]],
model_CV_Net_std$coef["scale(log(dollar_NSF))"][[1]],
model_CV_Net_std$coef["scale(log(num_nsf))"][[1]],
model_CV_Net_std$coef["scale(log(dollar_NIH))"][[1]],
model_CV_Net_std$coef["scale(log(num_nih))"][[1]],
model_CV_Net_std$coef["scale(log(C_PR))"][[1]],
model_CV_Net_std$coef["scale(Chi)"][[1]],
model_CV_Net_std$coef["(Intercept)"][[1]])
# install.packages('plm')
# install.packages('sjstats')
library(sjstats)
library(plm)
library(dplyr)
ZERO_REPLACEMENT_CONSTANT <- 1
ZERO_REPLACEMENT_CONSTANT_NUM <- 1
ZERO_REPLACEMENT_CONSTANT_AMT <- 1
dat <- read.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
print(colnames(dat))
print(nrow(dat))
# Summarize the data characteristics
# head(dat)
# summary(dat)
# str(dat)
# Treat NA, zeros values
cols_NA <- unlist(lapply(dat, function(x) any(is.na(x))))
cols_0s <- unlist(lapply(dat, function(x) any(x==0)))
cols_NA <- cols_NA[cols_NA==T]
cols_0s <- cols_0s[cols_0s==T]
print(names(cols_NA))
print(names(cols_0s))
# Note: No NA values
# List of columns having 0s values
# [1] "i10index"       "mean_of_IF"     "num_nsf"        "t_deflated_nsf" "num_nih"        "t_deflated_nih"
# [7] "KTotal"         "KDirect"        "KMediated"      "Chi"            "BetCentrality"  "PRCentrality"
# Note: This way seems does not work really well
# Parameters of # of grants and total amount of grants are not close to the ones in the paper
# for (cname in names(cols_0s)) {
#  if (cname != 'PRCentrality') {
#    dat[cname] -> col
#    col[col==0] <- ZERO_REPLACEMENT_CONSTANT
#    dat[cname] <- col
#  }
# }
#
# Try this manual way
col_num_nsf <- dat$num_nsf
col_num_nsf[col_num_nsf==0] <- ZERO_REPLACEMENT_CONSTANT_NUM
dat$num_nsf <- col_num_nsf
col_num_nih <- dat$num_nih
col_num_nih[col_num_nih==0] <- ZERO_REPLACEMENT_CONSTANT_NUM
dat$num_nih <- col_num_nih
col_t_deflated_nsf <- dat$t_deflated_nsf
col_t_deflated_nsf[col_t_deflated_nsf==0] <- ZERO_REPLACEMENT_CONSTANT_AMT
dat$t_deflated_nsf <- col_t_deflated_nsf
col_t_deflated_nih <- dat$t_deflated_nih
col_t_deflated_nih[col_t_deflated_nih==0] <- ZERO_REPLACEMENT_CONSTANT_AMT
dat$t_deflated_nih <- col_t_deflated_nih
# Rename the column name
dat$C_i <- dat$t_pubs_citations
dat$r_i <- dat$SchoolRank
dat$dollar_NSF <- dat$t_deflated_nsf
dat$dollar_NIH <- dat$t_deflated_nih
dat$C_PR <- dat$PRCentrality
dat$C_B <- dat$BetCentrality
dat$O <- dat$XDIndicator
# dat %>% mutate(C_D=Degree)
# Remove old columns
# dat$t_pubs_citations <- NULL
# dat$SchoolRank <- NULL
# dat$t_deflated_nsf <- NULL
# dat$t_deflated_nih <- NULL
# dat$PRCentrality <- NULL
# dat$BetCentrality <- NULL
# Build models
# str(dat)
# Remove row having NA (Ex: pagerank). Only keep 3900 nodes in the network.
datNet <- dat %>% filter(C_PR > 0)
print(nrow(dat))
# Model a: CV-Net with PageRank Centrality (without standardized)
model_a <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_a)
# Summary
# Model a (PR):
c(model_a$coef["log(r_i)"][[1]],
model_a$coef["log(h_index)"][[1]],
model_a$coef["log(dollar_NSF)"][[1]],
model_a$coef["log(num_nsf)"][[1]],
model_a$coef["log(dollar_NIH)"][[1]],
model_a$coef["log(num_nih)"][[1]],
model_a$coef["log(C_PR)"][[1]],
model_a$coef["Chi"][[1]],
model_a$coef["(Intercept)"][[1]])
model_b <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_B) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_b)
datNet <- dat %>% filter(C_B > 0)
model_b <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_B) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_b)
print(nrow(datNet))
dat$C_D <- dat$KTotal
# Model b: CV-Net with Betweeness Centrality (without standardized)
datNet <- dat %>% filter(C_D > 0)
print(nrow(datNet))
dat$C_D <- dat$KDirect
# Model b: CV-Net with Betweeness Centrality (without standardized)
datNet <- dat %>% filter(C_D > 0)
print(nrow(datNet))
model_c <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_D) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_c)
# Model a: CV-Net with PageRank Centrality (without standardized)
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_d <- lm(log(C_i) ~ log(r_i) + log(h_index)
+ log(dollar_NSF) + log(dollar_NIH)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_d)
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_e <- lm(log(C_i) ~ log(h_index)
+ log(dollar_NSF) + log(num_nsf)
+ log(dollar_NIH) + log(num_nih)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_e)
# install.packages('plm')
# install.packages('sjstats')
library(sjstats)
library(plm)
library(dplyr)
ZERO_REPLACEMENT_CONSTANT <- 1
ZERO_REPLACEMENT_CONSTANT_NUM <- 1
ZERO_REPLACEMENT_CONSTANT_AMT <- 1
dat <- read.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
print(colnames(dat))
print(nrow(dat))
# Summarize the data characteristics
# head(dat)
# summary(dat)
# str(dat)
# Treat NA, zeros values
cols_NA <- unlist(lapply(dat, function(x) any(is.na(x))))
cols_0s <- unlist(lapply(dat, function(x) any(x==0)))
cols_NA <- cols_NA[cols_NA==T]
cols_0s <- cols_0s[cols_0s==T]
print(names(cols_NA))
print(names(cols_0s))
# Note: No NA values
# List of columns having 0s values
# [1] "i10index"       "mean_of_IF"     "num_nsf"        "t_deflated_nsf" "num_nih"        "t_deflated_nih"
# [7] "KTotal"         "KDirect"        "KMediated"      "Chi"            "BetCentrality"  "PRCentrality"
# Note: This way seems does not work really well
# Parameters of # of grants and total amount of grants are not close to the ones in the paper
# for (cname in names(cols_0s)) {
#  if (cname != 'PRCentrality') {
#    dat[cname] -> col
#    col[col==0] <- ZERO_REPLACEMENT_CONSTANT
#    dat[cname] <- col
#  }
# }
#
# Try this manual way
col_num_nsf <- dat$num_nsf
col_num_nsf[col_num_nsf==0] <- ZERO_REPLACEMENT_CONSTANT_NUM
dat$num_nsf <- col_num_nsf
col_num_nih <- dat$num_nih
col_num_nih[col_num_nih==0] <- ZERO_REPLACEMENT_CONSTANT_NUM
dat$num_nih <- col_num_nih
col_t_deflated_nsf <- dat$t_deflated_nsf
col_t_deflated_nsf[col_t_deflated_nsf==0] <- ZERO_REPLACEMENT_CONSTANT_AMT
dat$t_deflated_nsf <- col_t_deflated_nsf
col_t_deflated_nih <- dat$t_deflated_nih
col_t_deflated_nih[col_t_deflated_nih==0] <- ZERO_REPLACEMENT_CONSTANT_AMT
dat$t_deflated_nih <- col_t_deflated_nih
# Rename the column name
dat$C_i <- dat$t_pubs_citations
dat$r_i <- dat$SchoolRank
dat$dollar_NSF <- dat$t_deflated_nsf
dat$dollar_NIH <- dat$t_deflated_nih
dat$C_PR <- dat$PRCentrality
dat$C_B <- dat$BetCentrality
dat$C_D <- dat$KDirect
dat$O <- dat$XDIndicator
# Remove old columns
# dat$t_pubs_citations <- NULL
# dat$SchoolRank <- NULL
# dat$t_deflated_nsf <- NULL
# dat$t_deflated_nih <- NULL
# dat$PRCentrality <- NULL
# dat$BetCentrality <- NULL
# Build models
# str(dat)
# Model a: CV-Net with PageRank Centrality (without standardized)
# Remove row having NA (Ex: pagerank). Only keep 3900 nodes in the network.
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_a <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_a)
# Model b: CV-Net with Betweeness Centrality (without standardized)
datNet <- dat %>% filter(C_B > 0)
print(nrow(datNet))
model_b <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_B) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_b)
# Model c: CV-Net with Degree Centrality (without standardized)
datNet <- dat %>% filter(C_D > 0)
print(nrow(datNet))
model_c <- lm(log(C_i) ~ log(r_i) + log(h_index) + log(dollar_NSF)
+ log(num_nsf) + log(dollar_NIH) + log(num_nih)
+ log(C_D) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_c)
# Model d: CV-Net with PageRank Centrality and without N1, N2 (without standardized)
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_d <- lm(log(C_i) ~ log(r_i) + log(h_index)
+ log(dollar_NSF) + log(dollar_NIH)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_d)
# Model d: CV-Net with PageRank Centrality and without School rank (without standardized)
datNet <- dat %>% filter(C_PR > 0)
print(nrow(datNet))
model_e <- lm(log(C_i) ~ log(h_index)
+ log(dollar_NSF) + log(num_nsf)
+ log(dollar_NIH) + log(num_nih)
+ log(C_PR) + Chi
+ factor(O) + factor(Y05yr), data=datNet)
summary(model_e)
dat <- read.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
head(dat)
max(dat$t_deflated_nih)
# install.packages('plm')
# install.packages('sjstats')
library(sjstats)
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_xd.csv')
print(colnames(dat))
print(nrow(dat))
head(dat)
# Remove row having NA (Ex: pagerank)
dat <- na.omit(dat)
# summary(dat)
# str(dat)
nrow(dat)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE)
# Model: FE (Standardized)
model_FE_std <- plm(z ~ scale(ln_a) + scale(tau) + scale(I) + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE_std)
# install.packages('plm')
# install.packages('sjstats')
library(sjstats)
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_xd.csv')
print(colnames(dat))
print(nrow(dat))
head(dat)
# Remove row having NA (Ex: pagerank)
dat <- na.omit(dat)
# summary(dat)
# str(dat)
nrow(dat)
# Model: No FE
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + PR + lamda, data=dat)
# summary(dat)
str(dat)
# Model: No FE
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + PR + lamda + factor(dept), data=dat)
summary(model_NoFE)
# Model: FE (Standardized)
model_FE_std <- plm(z ~ scale(ln_a) + scale(tau) + scale(I) + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
nrow(dat$ln_a)
dat$ln_a
len(dat$ln_a)
lenght(dat$ln_a)
length(dat$ln_a)
length(dat$I)
length(dat$tau)
scale(dat$ln_a)
dat %>% mutate(ln_a_scaled=scale(dat$ln_a),
tau_scaled=scale(dat$tau),
I_scaled=scale(dat$I))
model_FE_std <- plm(z ~ ln_a_scaled + tau_scaled + I_scaled + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
str(dat)
# Model: FE (Standardized)
dat %>% mutate(ln_a_scaled=scale(dat$ln_a))
str(dat)
# Model: FE (Standardized)
dat$ln_a_scaled <- scale(dat$ln_a)
str(dat)
dat$ln_a_scaled
# Model: FE (Standardized)
dat$ln_a_scaled <- NULL
dat <- dat %>% mutate(ln_a_scaled=scale(dat$ln_a),
tau_scaled=scale(dat$tau),
I_scaled=scale(dat$I))
str(dat)
model_FE_std <- plm(z ~ ln_a_scaled + tau_scaled + I_scaled + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE_std)
Oneway (individual) effect Within Model
# Call:
# plm(formula = z ~ ln_a_scaled + tau_scaled + I_scaled + factor(t),
#     data = dat, effect = "individual", model = "within", index = c("i",
#         "X"))
# Unbalanced Panel: n = 1247, T = 3-1388, N = 166621
# Residuals:
#      Min.   1st Qu.    Median   3rd Qu.      Max.
# -3.612039 -0.630061  0.031691  0.635723  5.373274
# Coefficients: (1 dropped because of singularities)
#                 Estimate Std. Error t-value  Pr(>|t|)
# ln_a_scaled    0.2523839  0.0028171 89.5899 < 2.2e-16 ***
# tau_scaled    -0.0662938  0.0271938 -2.4378 0.0147768 *
# I_scaled       0.0170185  0.0024670  6.8985 5.276e-12 ***
# (Note: Coefficients of dummy variable t are removed for shortenning)
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Total Sum of Squares:    156870
# Residual Sum of Squares: 149220
# R-Squared:      0.048815
# Adj. R-Squared: 0.041376
# F-statistic: 180.524 on 47 and 165327 DF, p-value: < 2.22e-16
model_FE_std <- plm(z ~ ln_a_scaled + tau_scaled + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE_std)
# Model: FE
# lmer
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE)
interception_FE <- mean(fixef(model_FE))
print(paste0('Interception: ', interception_FE))
