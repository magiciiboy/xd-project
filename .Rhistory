for (row in 1:n2nd) {
cc_str = df_2nd[row, "coauthor_codes"]
if(!is.null(cc_str) && !is.na(cc_str)) {
cc = strsplit(as.character(cc_str), ',')[[1]]
coauthors_2nd <- c(coauthors_2nd, cc)
}
}
coauthors_2nd <- unique(coauthors_2nd[coauthors_2nd!="0"
& coauthors_2nd!="1"
& coauthors_2nd!="2"
& coauthors_2nd!=s2nd])
pollinators_2nd <- coauthors_2nd[coauthors_2nd %in% c("0", "1", "2")]
#print(coauthors_1st)
#print(coauthors_2nd)
print("Wei Wang")
print(paste("No. of papers:", n1st))
print(paste("No. of coauthors:", length(coauthors_1st)))
print(paste("No. of pollinators:", length(pollinators_1st)))
print("Eric Lander")
print(paste("No. of papers:", n2nd))
print(paste("No. of coauthors:", length(coauthors_2nd)))
print(paste("No. of pollinators:", length(pollinators_2nd)))
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
cols <- c("google_id", "year", "citations", "coauthor_codes")
colnames(df_papers) <- cols
s1st <- "UedS9LQAAAAJ"
s2nd <- "LXVfPc8AAAAJ"
df_1st = filter(df_papers, (google_id==s1st | grepl(s1st, coauthor_codes)))
df_2nd <- filter(df_papers, (google_id==s2nd | grepl(s2nd, coauthor_codes)))
n1st <- nrow(df_1st)
n2nd <- nrow(df_2nd)
coauthors_1st = c()
coauthors_2nd = c()
for (row in 1:n1st) {
cc_str = df_1st[row, "coauthor_codes"]
if(!is.null(cc_str) && !is.na(cc_str)) {
cc = strsplit(as.character(cc_str), ',')[[1]]
coauthors_1st <- c(coauthors_1st, cc)
}
}
direct_coauthors_1st <- unique(coauthors_1st[coauthors_1st!="0"
& coauthors_1st!="1"
& coauthors_1st!="2"
& coauthors_1st!=s1st])
pollinators_1st <- coauthors_1st[coauthors_1st=="0"
| coauthors_1st=="1"
| coauthors_1st=="2"]
for (row in 1:n2nd) {
cc_str = df_2nd[row, "coauthor_codes"]
if(!is.null(cc_str) && !is.na(cc_str)) {
cc = strsplit(as.character(cc_str), ',')[[1]]
coauthors_2nd <- c(coauthors_2nd, cc)
}
}
direct_coauthors_2nd <- unique(coauthors_2nd[coauthors_2nd!="0"
& coauthors_2nd!="1"
& coauthors_2nd!="2"
& coauthors_2nd!=s2nd])
pollinators_2nd <- coauthors_2nd[coauthors_2nd %in% c("0", "1", "2")]
#print(coauthors_1st)
#print(coauthors_2nd)
print("Wei Wang")
print(paste("No. of papers:", n1st))
print(paste("No. of coauthors:", length(direct_coauthors_1st)))
print(paste("No. of pollinators:", length(pollinators_1st)))
print("Eric Lander")
print(paste("No. of papers:", n2nd))
print(paste("No. of coauthors:", length(direct_coauthors_2nd)))
print(paste("No. of pollinators:", length(pollinators_2nd)))
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
cols <- c("google_id", "year", "citations", "coauthor_codes")
colnames(df_papers) <- cols
s1st <- "UedS9LQAAAAJ"
s2nd <- "LXVfPc8AAAAJ"
df_1st = filter(df_papers, (google_id==s1st | grepl(s1st, coauthor_codes)))
df_2nd <- filter(df_papers, (google_id==s2nd | grepl(s2nd, coauthor_codes)))
n1st <- nrow(df_1st)
n2nd <- nrow(df_2nd)
coauthors_1st = c()
coauthors_2nd = c()
for (row in 1:n1st) {
cc_str = df_1st[row, "coauthor_codes"]
if(!is.null(cc_str) && !is.na(cc_str)) {
cc = strsplit(as.character(cc_str), ',')[[1]]
coauthors_1st <- c(coauthors_1st, cc)
}
}
direct_coauthors_1st <- coauthors_1st[coauthors_1st!="0"
& coauthors_1st!="1"
& coauthors_1st!="2"
& coauthors_1st!=s1st]
pollinators_1st <- coauthors_1st[coauthors_1st=="0"
| coauthors_1st=="1"
| coauthors_1st=="2"]
for (row in 1:n2nd) {
cc_str = df_2nd[row, "coauthor_codes"]
if(!is.null(cc_str) && !is.na(cc_str)) {
cc = strsplit(as.character(cc_str), ',')[[1]]
coauthors_2nd <- c(coauthors_2nd, cc)
}
}
direct_coauthors_2nd <- coauthors_2nd[coauthors_2nd!="0"
& coauthors_2nd!="1"
& coauthors_2nd!="2"
& coauthors_2nd!=s2nd]
pollinators_2nd <- coauthors_2nd[coauthors_2nd %in% c("0", "1", "2")]
#print(coauthors_1st)
#print(coauthors_2nd)
print("Wei Wang")
print(paste("No. of papers:", n1st))
print(paste("No. of coauthors:", length(unique(direct_coauthors_1st))))
print(paste("Ratio of pollinators:", length(pollinators_1st) / length(coauthors_1st)))
print("Eric Lander")
print(paste("No. of papers:", n2nd))
print(paste("No. of coauthors:", length(unique(direct_coauthors_2nd))))
print(paste("Ratio of pollinators:", length(pollinators_2nd) / length(coauthors_2nd)))
# This script generate output used in Gephi Application to
# create the network graph.
# There are 2 files to generate:
# - Nodes: (id, label, interval, size)
# - Edges: (source, target, type, id, label, interval, weight)
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
# Functions
splitPapersByYear <- function() {
# This function splits the data by published year of
# a paper. Base on those preprocessed sub-dataset we
# will create nodes and edges for each year.
# According to the paper, the research orientation of
# each falcuty can shift from an original department
# to a cross-disciplinary at the year of cross-disciplinary
# paper has been published.
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990, 1995, 2000, 2005, 2010, 2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - 5))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Elimiate nodes having no edges
df_nodes_cleaned <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes_cleaned) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
for (row in 1:nrow(df_nodes)) {
gid <- as.character(df_nodes[row, "Id"])
node_degree <- calculateNodeDegree(df_edges, gid)
if( node_degree > 0 ) {
xd <- (as.character(df_nodes[row, "Orientation"]) == 'XD')
node_coauthors <- getCoauthors(df_edges, gid)
node_orientation <- ifelse(xd, 'XD', getScholarOrientation(df_nodes, gid, node_coauthors))
# Add node
df_nodes_cleaned <- addAuthorNode(df_nodes_cleaned, gid, orientation=node_orientation, k=node_degree)
}
}
# Save
write.csv(df_nodes_cleaned, paste0('./preprocessed/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/edges_year_', year, '.csv'))
return(T)
}
# Main
if (!DATA_SPLITTED_BY_YEARS) {
splitPapersByYear()
}
if (!DATA_PROCESSED_NODES_EDGES) {
#processEdgesAndNodesPerYear(1990)
#processEdgesAndNodesPerYear(1995)
#processEdgesAndNodesPerYear(2000)
#processEdgesAndNodesPerYear(2005)
#processEdgesAndNodesPerYear(2010)
#processEdgesAndNodesPerYear(2015)
}
# This script generate output used in Gephi Application to
# create the network graph.
# There are 2 files to generate:
# - Nodes: (id, label, interval, size)
# - Edges: (source, target, type, id, label, interval, weight)
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
# Functions
splitPapersByYear <- function(bin=5) {
# This function splits the data by published year of
# a paper. Base on those preprocessed sub-dataset we
# will create nodes and edges for each year.
# According to the paper, the research orientation of
# each falcuty can shift from an original department
# to a cross-disciplinary at the year of cross-disciplinary
# paper has been published.
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990, 1995, 2000, 2005, 2010, 2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - bin))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Elimiate nodes having no edges
df_nodes_cleaned <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes_cleaned) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
for (row in 1:nrow(df_nodes)) {
gid <- as.character(df_nodes[row, "Id"])
node_degree <- calculateNodeDegree(df_edges, gid)
if( node_degree > 0 ) {
xd <- (as.character(df_nodes[row, "Orientation"]) == 'XD')
node_coauthors <- getCoauthors(df_edges, gid)
node_orientation <- ifelse(xd, 'XD', getScholarOrientation(df_nodes, gid, node_coauthors))
# Add node
df_nodes_cleaned <- addAuthorNode(df_nodes_cleaned, gid, orientation=node_orientation, k=node_degree)
}
}
# Save
write.csv(df_nodes_cleaned, paste0('./preprocessed/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/edges_year_', year, '.csv'))
return(T)
}
# Main
if (!DATA_SPLITTED_BY_YEARS) {
splitPapersByYear()
}
if (!DATA_PROCESSED_NODES_EDGES) {
processEdgesAndNodesPerYear(1990)
#processEdgesAndNodesPerYear(1995)
#processEdgesAndNodesPerYear(2000)
#processEdgesAndNodesPerYear(2005)
#processEdgesAndNodesPerYear(2010)
#processEdgesAndNodesPerYear(2015)
}
# This script generate output used in Gephi Application to
# create the network graph.
# There are 2 files to generate:
# - Nodes: (id, label, interval, size)
# - Edges: (source, target, type, id, label, interval, weight)
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
# Functions
splitPapersByYear <- function(bin=5) {
# This function splits the data by published year of
# a paper. Base on those preprocessed sub-dataset we
# will create nodes and edges for each year.
# According to the paper, the research orientation of
# each falcuty can shift from an original department
# to a cross-disciplinary at the year of cross-disciplinary
# paper has been published.
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990, 1995, 2000, 2005, 2010, 2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - bin))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Elimiate nodes having no edges
df_nodes_cleaned <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes_cleaned) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
for (row in 1:nrow(df_nodes)) {
gid <- as.character(df_nodes[row, "Id"])
node_degree <- calculateNodeDegree(df_edges, gid)
if( node_degree > 0 ) {
xd <- (as.character(df_nodes[row, "Orientation"]) == 'XD')
node_coauthors <- getCoauthors(df_edges, gid)
node_orientation <- ifelse(xd, 'XD', getScholarOrientation(df_nodes, gid, node_coauthors))
# Add node
df_nodes_cleaned <- addAuthorNode(df_nodes_cleaned, gid, orientation=node_orientation, k=node_degree)
}
}
# Save
write.csv(df_nodes_cleaned, paste0('./preprocessed/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/edges_year_', year, '.csv'))
return(T)
}
# Main
if (!DATA_SPLITTED_BY_YEARS) {
splitPapersByYear()
}
if (!DATA_PROCESSED_NODES_EDGES) {
# processEdgesAndNodesPerYear(1990)
processEdgesAndNodesPerYear(1995)
processEdgesAndNodesPerYear(2000)
processEdgesAndNodesPerYear(2005)
#processEdgesAndNodesPerYear(2010)
#processEdgesAndNodesPerYear(2015)
}
# This script generate output used in Gephi Application to
# create the network graph.
# There are 2 files to generate:
# - Nodes: (id, label, interval, size)
# - Edges: (source, target, type, id, label, interval, weight)
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
# Functions
splitPapersByYear <- function(bin=5) {
# This function splits the data by published year of
# a paper. Base on those preprocessed sub-dataset we
# will create nodes and edges for each year.
# According to the paper, the research orientation of
# each falcuty can shift from an original department
# to a cross-disciplinary at the year of cross-disciplinary
# paper has been published.
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990, 1995, 2000, 2005, 2010, 2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - bin))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Elimiate nodes having no edges
df_nodes_cleaned <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes_cleaned) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
for (row in 1:nrow(df_nodes)) {
gid <- as.character(df_nodes[row, "Id"])
node_degree <- calculateNodeDegree(df_edges, gid)
if( node_degree > 0 ) {
xd <- (as.character(df_nodes[row, "Orientation"]) == 'XD')
node_coauthors <- getCoauthors(df_edges, gid)
node_orientation <- ifelse(xd, 'XD', getScholarOrientation(df_nodes, gid, node_coauthors))
# Add node
df_nodes_cleaned <- addAuthorNode(df_nodes_cleaned, gid, orientation=node_orientation, k=node_degree)
}
}
# Save
write.csv(df_nodes_cleaned, paste0('./preprocessed/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/edges_year_', year, '.csv'))
return(T)
}
# Main
if (!DATA_SPLITTED_BY_YEARS) {
splitPapersByYear()
}
if (!DATA_PROCESSED_NODES_EDGES) {
# processEdgesAndNodesPerYear(1990)
# processEdgesAndNodesPerYear(1995)
# processEdgesAndNodesPerYear(2000)
# processEdgesAndNodesPerYear(2005)
processEdgesAndNodesPerYear(2010)
processEdgesAndNodesPerYear(2015)
}
