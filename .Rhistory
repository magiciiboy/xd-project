# Author: Tung Huynh
# Ref: https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf
library(ggplot2)
library(tidyr)
FILE_NAME = "./preprocessed/collaborations_xd_fraction.csv"
fraction_data <- read.csv(FILE_NAME)
max_xd = max(c(max(fraction_data$xd_direct), max(fraction_data$xd_mediate)))
axis_x_seq = seq(1980,2015,2)
fraction_data %>%
gather(key, fraction, xd_direct, xd_mediate) %>%
ggplot(aes(x=year, y=fraction, colour=key)) +
annotate("rect", xmin = 1990, ymin = 0, xmax= 2003, ymax = 0.3, fill="#f7e2ae") +
annotate("text", label="HGP (1990-2003)", x=1996.5, y=0.29) +
geom_line(size=1) +
scale_color_manual(values=c('#0000FF','#FF0000'),
labels=c("Direct XD links - Career data", "Mediated XD links - Career data"),
name="",
aesthetics = "colour") +
theme_classic() +
scale_x_continuous(limits = c(1980,2015), expand = c(0, 0)) +
scale_y_continuous(limits = c(0,0.3), expand = c(0, 0)) +
xlab("") +
ylab(expression(paste("Fraction of collaborations \nthat are cross-disciplinary"))) +
theme(axis.text.x = element_text(color="#000000", size=14, angle=0),
axis.text.y = element_text(color="#000000", size=14, angle=0),
plot.margin = margin(1, 1, 1, 1, "cm"),
legend.justification=c(0,0),
legend.position=c(0.01,0.6),
legend.background = element_rect(fill=alpha('white', 1.0))) +
scale_x_continuous(breaks=seq(1980,2015,2),
labels=ifelse(axis_x_seq %in% c(1980, 1990, 2000, 2010), axis_x_seq, "")) +
scale_fill_discrete(name="Test")
ggsave("./output/Fig2B.png", width = 7.0, height = 4.5, units="in")
# Author: Tung Huynh
# Ref: https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf
library(ggplot2)
library(tidyr)
FILE_NAME = "./preprocessed/collaborations_xd_fraction.csv"
fraction_data <- read.csv(FILE_NAME)
max_xd = max(c(max(fraction_data$xd_direct), max(fraction_data$xd_mediate)))
axis_x_seq = seq(1980,2015,2)
fraction_data %>%
gather(key, fraction, xd_direct, xd_mediate) %>%
ggplot(aes(x=year, y=fraction, colour=key)) +
annotate("rect", xmin = 1990, ymin = 0, xmax= 2003, ymax = 0.3, fill="#f7e2ae") +
annotate("text", label="HGP (1990-2003)", x=1996.5, y=0.29) +
geom_line(size=1) +
scale_color_manual(values=c('#0000FF','#FF0000'),
labels=c("Direct XD links - Career data", "Mediated XD links - Career data"),
name="",
aesthetics = "colour") +
theme_classic() +
scale_x_continuous(limits = c(1980,2015), expand = c(0, 0)) +
scale_y_continuous(limits = c(0,0.3), expand = c(0, 0)) +
xlab("") +
ylab(expression(paste("Fraction of collaborations \nthat are cross-disciplinary"))) +
theme(axis.text.x = element_text(color="#000000", size=14, angle=0),
axis.text.y = element_text(color="#000000", size=14, angle=0),
plot.margin = margin(1, 1, 1, 1, "cm"),
legend.justification=c(0,0),
legend.position=c(0.01,0.6),
legend.background = element_rect(fill=alpha('white', 1.0))) +
scale_x_continuous(breaks=seq(1980,2015,2),
labels=ifelse(axis_x_seq %in% c(1980, 1990, 2000, 2010), axis_x_seq, "")) +
scale_fill_discrete(name="Test")
ggsave("./output/Fig2B.png", width = 7.0, height = 4.5, units="in")
% !Rnw root = ../ProjectReport.Rnw
\begin{figure}[!htb]
\centering
\includegraphics[width=10cm, height=7cm]{Fig2B.png}
\caption{Evolution of the fraction of cross-disciplinary collaboration links}
\label{fig:2B}
\end{figure}
This figure depicts the evolution of the fraction of collaboration links in the network that are cross-disciplinary. While blue line illustrate the direct $XD$ links, the red line represent the mediated $XD$ links by pollinators. The orange area in the middle annotates the HGP project period from 1990 to 2013.
According to our observation, during the HGP project period (1990-2003), the ratio of direct and mediate $XD$ collaboration steadily keeps having a mild increase. This change marks the strong establishment of cross-disciplinary collaboration. The effectiveness of that collaboration only remarkably exhibits from 2005 to later when the number of mediate links increases sharply and reachs almost 30%% by 2015. This can be explained by the robustness of the internal network of each individual affiliation and the development of the cross-disciplinary links.
NA | 'abc'
NA || 'abc'
ifelse()
ifelse(NA, 'abc', 'efd')
x = ifelse(NA, 'abc', 'efd')
x
x = ifelse(!is.na(NA), 'abc', 'efd')
x
# Author: Tung Huynh
library(tidyr)
FILE_NAME = "./preprocessed/collaborations_xd_fraction.csv"
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
PAPERS_SPLITTED_BY_YEAR = T
CALCULATED_EDGES_PER_YEAR = T
CALCULATED_FRACTION = T
# Functions
splitPapersByYear <- function(bin=1) {
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990:2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - bin))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/2b/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/2b/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid, add_mediate_links=T)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Save
write.csv(df_nodes, paste0('./preprocessed/2b/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/2b/edges_year_', year, '.csv'))
return(T)
}
aggreateEdgesForYears <- function() {
df_fraction <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_fraction) <- c('xd_direct', 'xd_mediate', 'year')
xd_direct_count <- 0
xd_mediate_count <- 0
total_count <- 0
for (year in years) {
df_edges_year = read.csv(paste0('./preprocessed/2b/edges_year_', year, '.csv'))
xd_direct_count <- nrow(filter(df_edges_year, Type == 'Direct'))
xd_mediate_count <- nrow(filter(df_edges_year, Type == 'Mediate'))
xd_direct <- xd_direct_count / 2 * total_count
xd_mediate <- xd_mediate_count / 2 * total_count
df_fraction[nrow(df_fraction) + 1,] <- list(
xd_direct,
xd_mediate,
year
)
}
write.csv(FILE_NAME, df_fraction)
}
if (!PAPERS_SPLITTED_BY_YEAR) {
splitPapersByYear()
}
if (!CALCULATED_EDGES_PER_YEAR) {
years = c(1990:2015)
for(year in years) {
processEdgesAndNodesPerYear(year)
}
}
if (!CALCULATED_FRACTION) {
aggreateEdgesForYears()
}
# Author: Tung Huynh
library(tidyr)
FILE_NAME = "./preprocessed/collaborations_xd_fraction.csv"
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
PAPERS_SPLITTED_BY_YEAR = T
CALCULATED_EDGES_PER_YEAR = T
CALCULATED_FRACTION = T
# Functions
splitPapersByYear <- function(bin=1) {
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990:2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - bin))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/2b/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/2b/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid, add_mediate_links=T)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Save
write.csv(df_nodes, paste0('./preprocessed/2b/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/2b/edges_year_', year, '.csv'))
return(T)
}
aggreateEdgesForYears <- function() {
df_fraction <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_fraction) <- c('xd_direct', 'xd_mediate', 'year')
xd_direct_count <- 0
xd_mediate_count <- 0
total_count <- 0
for (year in years) {
df_edges_year = read.csv(paste0('./preprocessed/2b/edges_year_', year, '.csv'))
xd_direct_count <- nrow(filter(df_edges_year, Type == 'Direct'))
xd_mediate_count <- nrow(filter(df_edges_year, Type == 'Mediate'))
xd_direct <- xd_direct_count / 2 * total_count
xd_mediate <- xd_mediate_count / 2 * total_count
df_fraction[nrow(df_fraction) + 1,] <- list(
xd_direct,
xd_mediate,
year
)
}
write.csv(FILE_NAME, df_fraction)
}
if (!PAPERS_SPLITTED_BY_YEAR) {
splitPapersByYear()
}
if (!CALCULATED_EDGES_PER_YEAR) {
years = c(1990:2015)
for(year in years) {
processEdgesAndNodesPerYear(year)
}
}
if (!CALCULATED_FRACTION) {
aggreateEdgesForYears()
}
# Author: Tung Huynh
# This script generate output used in Gephi Application to
# create the network graph.
# There are 2 files to generate:
# - Nodes: (id, label, interval, size)
# - Edges: (source, target, type, id, label, interval, weight)
library(dplyr)
source('./Fig2Config.R')
source('./Fig2Scholar.R')
source('./Fig2Graph.R')
# Functions
splitPapersByYear <- function(bin=5) {
# This function splits the data by published year of
# a paper. Base on those preprocessed sub-dataset we
# will create nodes and edges for each year.
# According to the paper, the research orientation of
# each falcuty can shift from an original department
# to a cross-disciplinary at the year of cross-disciplinary
# paper has been published.
df_papers = read.csv('./data/GoogleScholar_paper_stats.csv')
years = c(1990, 1995, 2000, 2005, 2010, 2015)
cols <- c("google_id", "year", "citations", "coauthor_codes")
# Five year bin
for (year in years) {
df_papers_year = filter(df_papers, X2014 <= year & X2014 > (year - bin))
colnames(df_papers_year) <- cols
write.csv(df_papers_year, paste0('./preprocessed/papers_year_', year, '.csv'))
}
return(T)
}
processEdgesAndNodesPerYear <- function(year) {
df_papers <- read.csv(paste0('./preprocessed/papers_year_', year, '.csv'))
df_nodes <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
df_edges <- data.frame(matrix(ncol = 7, nrow = 0))
colnames(df_edges) <- c('Source', 'Target', 'Type', 'Id', 'Label', 'Interval', 'Weight')
# Read papers and create nodes and edges
for (row in 1:nrow(df_papers)) {
gid <- as.character(df_papers[row, "google_id"])
coauthor_codes <- as.character(df_papers[row, "coauthor_codes"])
coauthors <- unique(strsplit(coauthor_codes, ',')[[1]])
isXD = isCrossDisciplinaryByPollinators(coauthors)
orientation_xd = ifelse(isXD, 'XD', NA)
df_nodes <- addAuthorNode(df_nodes, gid, orientation = orientation_xd)
# Directed author
directed_coauthors = coauthors[coauthors != '0'
& coauthors != '1'
& coauthors != '2'
& coauthors != gid
& !is.na(coauthors)
& !is.null(coauthors)
& coauthors != '']
n_coauthors = length(directed_coauthors)
if(n_coauthors) {
for (row_dca in 1:n_coauthors) {
coauthor_gid <- directed_coauthors[row_dca]
# Add node and an edge to the falcuty
df_nodes <- addAuthorNode(df_nodes, coauthor_gid)
df_edges <- addEdge(df_edges, gid_source=gid, gid_target=coauthor_gid)
# Add edge between coauthors
if (n_coauthors > 1 && row_dca < n_coauthors) {
for (row_a_to_a in row_dca + 1:n_coauthors) {
next_coauthor_id <- directed_coauthors[row_a_to_a]
df_edges <- addEdge(df_edges, gid_source=coauthor_gid, gid_target=next_coauthor_id)
}
}
}
}
}
# Elimiate nodes having no edges
df_nodes_cleaned <- data.frame(matrix(ncol = 6, nrow = 0))
colnames(df_nodes_cleaned) <- c('Id', 'Label', 'Interval', 'Weight', 'Dept', 'Orientation')
for (row in 1:nrow(df_nodes)) {
gid <- as.character(df_nodes[row, "Id"])
node_degree <- calculateNodeDegree(df_edges, gid)
if( node_degree > 0 ) {
xd <- (as.character(df_nodes[row, "Orientation"]) == 'XD')
node_coauthors <- getCoauthors(df_edges, gid)
node_orientation <- ifelse(xd, 'XD', getScholarOrientation(df_nodes, gid, node_coauthors))
# Add node
df_nodes_cleaned <- addAuthorNode(df_nodes_cleaned, gid, orientation=node_orientation, k=node_degree)
}
}
# Save
write.csv(df_nodes_cleaned, paste0('./preprocessed/nodes_year_', year, '.csv'))
write.csv(df_edges, paste0('./preprocessed/edges_year_', year, '.csv'))
return(T)
}
# Main
if (!DATA_SPLITTED_BY_YEARS) {
splitPapersByYear()
}
if (!DATA_PROCESSED_NODES_EDGES) {
# processEdgesAndNodesPerYear(1990)
# processEdgesAndNodesPerYear(1995)
# processEdgesAndNodesPerYear(2000)
# processEdgesAndNodesPerYear(2005)
processEdgesAndNodesPerYear(2010)
processEdgesAndNodesPerYear(2015)
}
setwd('~/Google Drive (tunghuynh314)/school/COCS 6323/COCS 6323 - Group Project/')
dfBIO <- read.csv('./data/Biology_citations_stats_CitationNormalizationData.csv')
dfCS <- read.csv('./data/ComputerScience_citations_stats_CitationNormalizationData.csv')
dfAll <- cbind(dfBIO, dfCS)
dfAll <- rbind(dfBIO, dfCS)
dim(dfBIO)
dim(dfCS)
dfCitations <- read.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
dim(dfCitations)
ead.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
dim(dfC)
dfC <- read.csv('./data/Faculty_GoogleScholar_Funding_Data_N4190.csv')
dim(dfC)
install.packages('sjstats')
# Model: FE
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_xd.csv')
print(colnames(dat))
print(nrow(dat))
plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE)
# Model: FE (Standardized)
# install.packages('sjstats')
library(sjstats)
model_FE_std <- std_beta(model_FE)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE)
# Model: FE (Standardized)
# install.packages('sjstats')
library(sjstats)
model_FE_std <- std_beta(model_FE)
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_all.csv')
print(colnames(dat))
print(nrow(dat))
# summary(dat)
# str(dat)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="time")
summary(model_FE)
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_all.csv')
print(colnames(dat))
print(nrow(dat))
# summary(dat)
# str(dat)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="time")
summary(model_FE)
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_all.csv')
print(colnames(dat))
print(nrow(dat))
# summary(dat)
# str(dat)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="time")
summary(model_FE)
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_all.csv')
print(colnames(dat))
print(nrow(dat))
# summary(dat)
# str(dat)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="time")
summary(model_FE)
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_all.csv')
print(colnames(dat))
print(nrow(dat))
# summary(dat)
# str(dat)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="time")
summary(model_FE)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_xd.csv')
head(dat)
help(log)
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + log(PR) + log(lamda) + factor(dept), data=dat)
summary(model_NoFE)
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_xd.csv')
print(colnames(dat))
print(nrow(dat))
head(dat)
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + log(PR) + log(lamda) + factor(dept), data=dat)
summary(model_NoFE)
model_NoFE_std <- lm(scale(z) ~ scale(ln_a) + scale(tau) + scale(I) + factor(t) + scale(log(PR)) + scale(log(lamda)) + factor(dept), data=dat)
summary(model_NoFE_std)
model_NoFE_std <- lm(scale(z) ~ scale(ln_a) + scale(tau) + scale(I) + factor(t) + scale(log(PR)) + scale(log(lamda)) + factor(dept), data=dat)
model_NoFE_std <- lm(scale(z) ~ scale(ln_a) + scale(tau) + scale(I) + factor(t) + log(PR) + log(lamda) + factor(dept), data=dat)
# install.packages('plm')
library(plm)
library(dplyr)
dat <- read.csv('./preprocessed/S4S5/panel_model_paper_citations_data_xd.csv')
print(colnames(dat))
print(nrow(dat))
head(dat)
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + log(PR) + log(lamda) + factor(dept), data=dat)
summary(model_NoFE)
model_NoFE_std <- lm(scale(z) ~ scale(ln_a) + scale(tau) + scale(I) + factor(t) + log(PR) + log(lamda) + factor(dept), data=dat)
summary(model_NoFE_std)
# summary(dat)
# str(dat)
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + PR + lamda + factor(dept), data=dat)
summary(model_NoFE)
# summary(dat)
# str(dat)
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + PR + factor(dept), data=dat)
summary(model_NoFE)
+ lamda
# summary(dat)
# str(dat)
model_NoFE <- lm(z ~ ln_a + tau + I + factor(t) + PR + lamda + factor(dept), data=dat)
summary(model_NoFE)
model_NoFE_std <- lm(scale(z) ~ scale(ln_a) + scale(tau) + scale(I) + factor(t) + scale(PR) + scale(lamda) + factor(dept), data=dat)
summary(model_NoFE_std)
model_FE <- plm(z ~ ln_a + tau + I + factor(t), data=dat, index=c("i", "X"), model="within", effect="individual")
summary(model_FE)
# install.packages('plm')
library(plm)
